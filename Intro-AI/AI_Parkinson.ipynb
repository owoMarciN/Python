{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNySTTQM83zFflmbzeY/Zdg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owoMarciN/Python/blob/main/Intro-AI/AI_Parkinson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLDikd3j9zTm"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install --upgrade ucimlrepo\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo, list_available_datasets\n",
        "\n",
        "# check which datasets can be imported\n",
        "#list_available_datasets()\n",
        "\n",
        "# import dataset\n",
        "park = fetch_ucirepo(id=174)\n",
        "\n",
        "# access data\n",
        "X = park.data.features\n",
        "y = park.data.targets\n",
        "# train model e.g. sklearn.linear_model.LinearRegression().fit(X, y)\n",
        "\n",
        "# access metadata\n",
        "# print(park.metadata.uci_id)\n",
        "# print(park.metadata.num_instances)\n",
        "# print(park.metadata.additional_info.summary)\n",
        "\n",
        "# access variable info in tabular format\n",
        "# print(park.variables)"
      ],
      "metadata": {
        "id": "Il9HvPdP95rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "OJfRJmxS95z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SciKit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Dimension reduction\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "vL-H6LFy952D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "XlLHmtfK954n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the data\n",
        "\n",
        "# print(X.describe())\n",
        "# print(y)"
      ],
      "metadata": {
        "id": "K0dkMHI8-UD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class distribution plot\n",
        "\n",
        "sns.countplot(x=y['status'])\n",
        "plt.title(\"Class distribution\")\n",
        "plt.xlabel(\"Classes (0 - Healthy, 1 - Parkinson)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nH6IoHH79568"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_data = X[['MDVP:Fo', 'MDVP:Fhi', 'MDVP:Flo', 'MDVP:RAP', 'MDVP:PPQ']]\n",
        "\n",
        "sns.pairplot(pp_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N7qetY6X959G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim=30, hidden=16):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def get_optimizer(name, params, lr, momentum=0.9):\n",
        "    name = name.lower()\n",
        "    if name == \"sgd\":\n",
        "        return optim.SGD(params, lr=lr)\n",
        "    if name == \"momentum\":\n",
        "        return optim.SGD(params, lr=lr, momentum=momentum)\n",
        "    if name == \"adam\":\n",
        "        return optim.Adam(params, lr=lr)\n",
        "    if name == \"rmsprop\":\n",
        "        return optim.RMSprop(params, lr=lr, momentum=momentum)\n",
        "    raise ValueError(\"Unknown optimizer\")"
      ],
      "metadata": {
        "id": "lxizaOpQAimg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval(opt_name, lr, epochs, momentum, Xtr, Xte, ytr, yte, in_dim=30):\n",
        "    start_time = time.time()\n",
        "    model = MLP(in_dim=in_dim)\n",
        "    optimizer = get_optimizer(opt_name, model.parameters(), lr, momentum)\n",
        "    criterion = nn.BCELoss()\n",
        "    losses = []\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(Xtr)\n",
        "        loss = criterion(outputs, ytr)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_prob = model(Xte).numpy()\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    return losses, {\n",
        "            \"acc\": accuracy_score(yte, y_pred),\n",
        "            \"prec\": precision_score(yte, y_pred),\n",
        "            \"rec\": recall_score(yte, y_pred),\n",
        "            \"f1\": f1_score(yte, y_pred),\n",
        "            \"auc\": roc_auc_score(yte, y_prob)\n",
        "    }, elapsed_time"
      ],
      "metadata": {
        "id": "rp4n2DCeCGgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = StandardScaler().fit_transform(X).astype('float32')\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "Xtr, Xte = map(torch.tensor, (Xtr, Xte))\n",
        "ytr, yte = map (lambda v : torch.tensor(v.values).float(), (ytr, yte))"
      ],
      "metadata": {
        "id": "RdxZvOgdBSzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses, metrics, elapsed_time = train_and_eval(opt_name=\"adam\", lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr, Xte=Xte, ytr=ytr, yte=yte, in_dim=Xtr.shape[1])\n",
        "print(f\"Baseline metrics (opt_name=Adam)\\n {metrics}\")\n",
        "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
      ],
      "metadata": {
        "id": "7INtpHAKCNc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline MLP\n",
        "opt = [\"adam\", \"sgd\", \"momentum\", \"rmsprop\"]\n",
        "losses_all = []\n",
        "f1_all = []\n",
        "acc_all = []\n",
        "epochs = []\n",
        "elapsed_times = []\n",
        "\n",
        "for opt_name in opt:\n",
        "    losses, metrics, elapsed_time = train_and_eval(opt_name=opt_name, lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr, Xte=Xte, ytr=ytr, yte=yte, in_dim=Xtr.shape[1])\n",
        "    f1_all.append(metrics[\"f1\"])\n",
        "    acc_all.append(metrics[\"acc\"])\n",
        "    losses_all.append(losses)\n",
        "    elapsed_times.append(elapsed_time)\n",
        "\n",
        "for i, opt_name in enumerate(opt):\n",
        "    plt.plot(losses_all[i], label=opt_name)\n",
        "plt.legend()\n",
        "plt.savefig(\"lossfun.png\")\n",
        "plt.show()\n",
        "\n",
        "for i, opt_name in enumerate(opt):\n",
        "    print(f\"{opt_name:10s}  acc={acc_all[i]:.4f}  f1={f1_all[i]:.4f}  time={elapsed_times[i]:.4f}s\")"
      ],
      "metadata": {
        "id": "qXMjka55DO7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval(opt_name, lr, epochs, momentum, Xtr, Xte, ytr, yte, in_dim=30):\n",
        "    start_time = time.time()\n",
        "    model = MLP(in_dim=in_dim)\n",
        "    optimizer = get_optimizer(opt_name, model.parameters(), lr, momentum)\n",
        "    criterion = nn.BCELoss()\n",
        "    losses = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(Xtr)\n",
        "        loss = criterion(outputs, ytr)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_prob = model(Xte).numpy()\n",
        "        y_pred = (y_prob >= 0.5).astype(int)\n",
        "        f1_scores.append(f1_score(yte, y_pred))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_prob = model(Xte).numpy()\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    return losses, {\n",
        "            \"acc\": accuracy_score(yte, y_pred),\n",
        "            \"prec\": precision_score(yte, y_pred),\n",
        "            \"rec\": recall_score(yte, y_pred),\n",
        "            \"f1\": f1_score(yte, y_pred),\n",
        "            \"auc\": roc_auc_score(yte, y_prob)\n",
        "    }, elapsed_time, f1_scores"
      ],
      "metadata": {
        "id": "a_dYUYU-98hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline MLP\n",
        "opt = [\"adam\", \"sgd\", \"momentum\", \"rmsprop\"]\n",
        "losses_all = []\n",
        "f1_all = []\n",
        "acc_all = []\n",
        "epochs = []\n",
        "elapsed_times = []\n",
        "\n",
        "for opt_name in opt:\n",
        "    losses, metrics, elapsed_time, f1_scores = train_and_eval(opt_name=opt_name, lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr, Xte=Xte, ytr=ytr, yte=yte, in_dim=Xtr.shape[1])\n",
        "    f1_all.append(f1_scores)\n",
        "\n",
        "for i, opt_name in enumerate(opt):\n",
        "    plt.plot(f1_all[i], label=opt_name)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JQrVzzZV97ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "def train_and_eval(opt_name, lr, epochs, momentum, Xtr, Xte, ytr, yte, in_dim=30):\n",
        "    start_time = time.time()\n",
        "    model = MLP(in_dim=in_dim)\n",
        "    optimizer = get_optimizer(opt_name, model.parameters(), lr, momentum)\n",
        "    criterion = nn.BCELoss()\n",
        "    losses = []\n",
        "    l_rates = []\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "    for _ in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(Xtr)\n",
        "        loss = criterion(outputs, ytr)\n",
        "        loss.backward()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        l_rates.append(scheduler.get_last_lr())\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_prob = model(Xte).numpy()\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    return losses, {\n",
        "            \"acc\": accuracy_score(yte, y_pred),\n",
        "            \"prec\": precision_score(yte, y_pred),\n",
        "            \"rec\": recall_score(yte, y_pred),\n",
        "            \"f1\": f1_score(yte, y_pred),\n",
        "            \"auc\": roc_auc_score(yte, y_prob)\n",
        "    }, elapsed_time, l_rates\n"
      ],
      "metadata": {
        "id": "uMLzQgCP_XQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline MLP\n",
        "opt = [\"adam\", \"sgd\", \"momentum\", \"rmsprop\"]\n",
        "losses_all = []\n",
        "f1_all = []\n",
        "acc_all = []\n",
        "epochs = []\n",
        "elapsed_times = []\n",
        "lr_all = []\n",
        "\n",
        "for opt_name in opt:\n",
        "    losses, metrics, elapsed_time, l_rates = train_and_eval(opt_name=opt_name, lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr, Xte=Xte, ytr=ytr, yte=yte, in_dim=Xtr.shape[1])\n",
        "    f1_all.append(metrics[\"f1\"])\n",
        "    acc_all.append(metrics[\"acc\"])\n",
        "    losses_all.append(losses)\n",
        "    lr_all.append(l_rates)\n",
        "    elapsed_times.append(elapsed_time)\n",
        "\n",
        "for i, opt_name in enumerate(opt):\n",
        "    plt.plot(losses_all[i], label=opt_name)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for i, opt_name in enumerate(opt):\n",
        "    print(f\"{opt_name:10s}  acc={acc_all[i]:.4f}  f1={f1_all[i]:.4f}  time={elapsed_times[i]:.4f}s\")\n",
        "\n",
        "\n",
        "for i, opt_name in enumerate(opt):\n",
        "    plt.plot(lr_all[i])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "OXuM8XQFATFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans_features(X_train, X_test, n_clusters=8, random_state=42):\n",
        "    # Ensure inputs are NumPy arrays for KMeans and subsequent NumPy operations\n",
        "    if isinstance(X_train, torch.Tensor):\n",
        "        X_train_np = X_train.numpy()\n",
        "    else:\n",
        "        X_train_np = X_train\n",
        "\n",
        "    if isinstance(X_test, torch.Tensor):\n",
        "        X_test_np = X_test.numpy()\n",
        "    else:\n",
        "        X_test_np = X_test\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters,\n",
        "    n_init=10,\n",
        "    random_state=random_state)\n",
        "    kmeans.fit(X_train_np)\n",
        "\n",
        "    def to_dist(X_arr):\n",
        "        # X_arr will already be a NumPy array if the outer conversion happened\n",
        "        return np.linalg.norm(\n",
        "            X_arr[:, None, :] - kmeans.cluster_centers_[None, :, :],\n",
        "            axis=2\n",
        "            ).astype(\"float32\")\n",
        "\n",
        "    return to_dist(X_train_np), to_dist(X_test_np)"
      ],
      "metadata": {
        "id": "yioq_EtxJewU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr_km, Xte_km = kmeans_features(Xtr, Xte, n_clusters=8)\n",
        "\n",
        "Xtr_km = torch.tensor(Xtr_km, dtype=torch.float32)\n",
        "Xte_km = torch.tensor(Xte_km, dtype=torch.float32)\n",
        "\n",
        "losses, metrics, elapsed_time = train_and_eval(opt_name=\"adam\", lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr_km, Xte=Xte_km, ytr=ytr, yte=yte, in_dim=8)\n",
        "metrics"
      ],
      "metadata": {
        "id": "elH2xBObJkSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_features(X_train, X_test, var_threshold=0.95, random_state=42):\n",
        "    # PCA\n",
        "    pca = PCA(n_components=var_threshold, random_state=random_state)\n",
        "\n",
        "    pca.fit(X_train)\n",
        "\n",
        "    # Transformation train/test\n",
        "    X_train_pca = pca.transform(X_train).astype(\"float32\")\n",
        "    X_test_pca = pca.transform(X_test).astype(\"float32\")\n",
        "\n",
        "    # Number of components\n",
        "    n_components = pca.n_components_\n",
        "\n",
        "    print(f\"We used {n_components} PCA components, to get ≥{int(var_threshold*100)}% variation.\")\n",
        "\n",
        "    return X_train_pca, X_test_pca, n_components"
      ],
      "metadata": {
        "id": "v-MX0L_9JkVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr_pca, Xte_pca, n_components = pca_features(Xtr, Xte, var_threshold=0.95)\n",
        "\n",
        "Xtr_pca = torch.tensor(Xtr_pca, dtype=torch.float32)\n",
        "Xte_pca = torch.tensor(Xte_pca, dtype=torch.float32)\n",
        "\n",
        "losses, metrics, elapsed_time = train_and_eval(opt_name=\"adam\", lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr_pca, Xte=Xte_pca, ytr=ytr, yte=yte, in_dim=n_components)\n",
        "metrics"
      ],
      "metadata": {
        "id": "1zlSWsl2JkXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim=30, bottleneck_dim=8):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, bottleneck_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(bottleneck_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return out\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"Returns the 8-D bottleneck representation.\"\"\"\n",
        "        return self.encoder(x)\n"
      ],
      "metadata": {
        "id": "ie-LQfblJkZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def autoencoder_features(X_train, X_test, epochs=50, lr=1e-3):\n",
        "    input_dim = X_train.shape[1]\n",
        "    bottleneck_dim = 8\n",
        "\n",
        "    ae = Autoencoder(input_dim=input_dim, bottleneck_dim=bottleneck_dim)\n",
        "    optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    Xtr_tensor = X_train.float()\n",
        "\n",
        "    # Training loop\n",
        "    for _ in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        recon = ae(Xtr_tensor)\n",
        "        loss = loss_fn(recon, Xtr_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Extract 8-D features\n",
        "    with torch.no_grad():\n",
        "        Z_train = ae.encode(X_train.float())\n",
        "        Z_test  = ae.encode(X_test.float())\n",
        "\n",
        "    return Z_train, Z_test\n"
      ],
      "metadata": {
        "id": "GE4K8NrUJkcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr_ae, Xte_ae = autoencoder_features(Xtr, Xte, epochs=100, lr=1e-3)\n",
        "\n",
        "losses, metrics, elapsed_time = train_and_eval(opt_name=\"adam\", lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr_ae, Xte=Xte_ae, ytr=ytr, yte=yte, in_dim=8)\n",
        "metrics"
      ],
      "metadata": {
        "id": "jCkCGp_6Jkef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "ytr_np = ytr.numpy().ravel()\n",
        "\n",
        "# PCA 2D\n",
        "pca_2d = PCA(n_components=2)\n",
        "Xtr_pca_2d = pca_2d.fit_transform(Xtr_pca)  # Xtr should be NumPy\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "for label in np.unique(ytr_np):\n",
        "    plt.scatter(Xtr_pca_2d[ytr_np == label, 0], Xtr_pca_2d[ytr_np == label, 1], label=f\"Class {label}\")\n",
        "\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.title(\"2D PCA Projection\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w5Zn3mvQ8iSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytr_np = ytr.numpy().ravel()\n",
        "\n",
        "# PCA 2D\n",
        "pca_2d = PCA(n_components=2)\n",
        "Xtr_ae_2d = pca_2d.fit_transform(Xtr_ae)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "for label in np.unique(ytr_np):\n",
        "    plt.scatter(Xtr_ae_2d[ytr_np == label, 0], Xtr_ae_2d[ytr_np == label, 1], label=f\"Class {label}\")\n",
        "\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.title(\"2D AE Projection\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Save figure BEFORE showing it\n",
        "plt.savefig(\"2D_AE.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7n6eh0s388ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameters\n"
      ],
      "metadata": {
        "id": "l9w40F23IXK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler, NSGAIISampler\n",
        "from optuna.pruners import HyperbandPruner"
      ],
      "metadata": {
        "id": "Riqu05wYE8rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_space = {\n",
        "    \"lr\": [1e-4, 1e-3, 1e-2, 1e-1],\n",
        "    \"momentum\": [0.7, 0.8, 0.9, 0.99],\n",
        "    \"hidden_size\": [8, 16, 32],\n",
        "    \"weight_decay\": [0.001, 0.01],\n",
        "    \"batch_size\": [16, 32, 64]\n",
        "}"
      ],
      "metadata": {
        "id": "S4sdZGP7E7ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval_hparams(hparams):\n",
        "    start_time = time.time()\n",
        "    model = MLP(in_dim=Xtr.shape[1], hidden=hparams[\"hidden_size\"])\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=hparams[\"lr\"],\n",
        "        momentum=hparams[\"momentum\"]\n",
        "    )\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for _ in range(100):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(Xtr)\n",
        "        loss = criterion(outputs, ytr.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_prob = model(Xte).numpy()\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    # Return the final F1-score and the elapsed time\n",
        "    return f1_score(yte, y_pred), elapsed_time"
      ],
      "metadata": {
        "id": "ds7SdMTMCwyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    hp = {\n",
        "        \"lr\": trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True),\n",
        "        \"momentum\": trial.suggest_float(\"momentum\", 0.7, 0.99),\n",
        "        \"hidden_size\": trial.suggest_categorical(\"hidden_size\", [8, 16, 32]),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True),\n",
        "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "    }\n",
        "\n",
        "    f1_score_val, elapsed_time_val = train_and_eval_hparams(hp)\n",
        "    trial.set_user_attr(\"elapsed_time\", elapsed_time_val)\n",
        "    return f1_score_val"
      ],
      "metadata": {
        "id": "2ri9tTK9TB22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optuna Grid Search\n",
        "def run_optuna_grid_search(n_trials=25):\n",
        "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.GridSampler(search_space=search_space))\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "    trajectory = [t.value for t in study.trials]\n",
        "    performance = [t.user_attrs[\"elapsed_time\"] for t in study.trials]\n",
        "    return study.best_params, study.best_value, trajectory, performance"
      ],
      "metadata": {
        "id": "pHR7XkG4Cx2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optuna Random Search\n",
        "def run_optuna_random_search(n_trials=25):\n",
        "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler())\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "    trajectory = [t.value for t in study.trials]\n",
        "    performance = [t.user_attrs[\"elapsed_time\"] for t in study.trials]\n",
        "    return study.best_params, study.best_value, trajectory, performance"
      ],
      "metadata": {
        "id": "f9BG32RHCyCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian Optimization — Build surrogate model of performance.\n",
        "def run_bayesian_optimization(n_trials=25):\n",
        "    study = optuna.create_study(direction=\"maximize\", sampler=TPESampler())\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "    trajectory = [t.value for t in study.trials]\n",
        "    performance = [t.user_attrs[\"elapsed_time\"] for t in study.trials]\n",
        "    return study.best_params, study.best_value, trajectory, performance"
      ],
      "metadata": {
        "id": "_h79lGMICyGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperband / BOHB — Adaptive resource allocation.\n",
        "def run_hyperband(n_trials=25):\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\",\n",
        "        pruner=HyperbandPruner()\n",
        "    )\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "    trajectory = [t.value for t in study.trials]\n",
        "    performance = [t.user_attrs[\"elapsed_time\"] for t in study.trials]\n",
        "    return study.best_params, study.best_value, trajectory, performance"
      ],
      "metadata": {
        "id": "tRqa5JKkCyJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolutionary / Metaheuristic Search — GA, PSO, DE for AutoML.\n",
        "def run_evolutionary(n_trials=25):\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\",\n",
        "        sampler=NSGAIISampler()\n",
        "    )\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "    trajectory = [t.value for t in study.trials]\n",
        "    performance = [t.user_attrs[\"elapsed_time\"] for t in study.trials]\n",
        "    return study.best_params, study.best_value, trajectory, performance"
      ],
      "metadata": {
        "id": "cFpOJMLnCyND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "# Baselines\n",
        "results[\"Grid\"], results[\"Grid_f1\"], grid_traj, grid_performance = run_optuna_grid_search()\n",
        "results[\"Random\"], results[\"Random_f1\"], random_traj, random_performance = run_optuna_random_search(n_trials=25)\n",
        "\n",
        "# Advanced methods\n",
        "bo_hp, bo_f1, bo_traj, bo_performance = run_bayesian_optimization()\n",
        "hb_hp, hb_f1, hb_traj, hb_performance = run_hyperband()\n",
        "ev_hp, ev_f1, ev_traj, ev_performance = run_evolutionary()\n",
        "\n",
        "results[\"Bayes\"] = bo_hp; results[\"Bayes_f1\"] = bo_f1\n",
        "results[\"Hyperband\"] = hb_hp; results[\"Hyperband_f1\"] = hb_f1\n",
        "results[\"Evolutionary\"] = ev_hp; results[\"Evolutionary_f1\"] = ev_f1"
      ],
      "metadata": {
        "id": "plRMIdJbEvFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate trajectories and performances for consistent plotting, as Optuna Grid Search runs all combinations\n",
        "# while other methods are limited by n_trials (defaulting to 25).\n",
        "N_TRIALS_FOR_PLOT = 25\n",
        "plot_grid_traj = grid_traj[:N_TRIALS_FOR_PLOT]\n",
        "plot_grid_performance = grid_performance[:N_TRIALS_FOR_PLOT]\n",
        "\n",
        "# For random, bayesian, hyperband, and evolutionary searches, the trajectory length is N_TRIALS by definition.\n",
        "# We ensure all plotting uses N_TRIALS_FOR_PLOT where appropriate.\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(plot_grid_traj, label=\"Grid Search\")\n",
        "plt.plot(random_traj, label=\"Random Search\")\n",
        "plt.plot(bo_traj, label=\"Bayesian Opt\")\n",
        "plt.plot(hb_traj, label=\"Hyperband\")\n",
        "plt.plot(ev_traj, label=\"Evolutionary\")\n",
        "\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.ylabel(\"Best F1\")\n",
        "plt.title(\"Performance Trajectory\")\n",
        "plt.legend()\n",
        "plt.savefig(\"perTraj.png\") # Save figure before showing\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(plot_grid_performance, label=\"Grid Search\")\n",
        "plt.plot(random_performance, label=\"Random Search\")\n",
        "plt.plot(bo_performance, label=\"Bayesian Opt\")\n",
        "plt.plot(hb_performance, label=\"Hyperband\")\n",
        "plt.plot(ev_performance, label=\"Evolutionary\")\n",
        "\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.ylabel(\"Elapsed Time (s)\")\n",
        "plt.title(\"Elapsed Time per Trial\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mYWXTH33Evsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = pd.DataFrame({\n",
        "    \"Method\": [\"Grid\", \"Random\", \"Bayes\", \"Hyperband\", \"Evolutionary\"],\n",
        "    \"Best F1\": [results[\"Grid_f1\"], results[\"Random_f1\"], bo_f1, hb_f1, ev_f1],\n",
        "    \"Best Params\": [\n",
        "        results[\"Grid\"], results[\"Random\"], bo_hp, hb_hp, ev_hp\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(table)\n",
        "table.to_latex(index=False)"
      ],
      "metadata": {
        "id": "amYcxbOAEziT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Everything together - Optimizers $\\times$ Reduction Techniques $\\times$ Hyper-parameters\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "ZRNr8TopVdKw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZdDKMZRCVHGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = [\"adam\", \"sgd\", \"momentum\", \"rmsprop\"]\n",
        "all_metrics = []\n",
        "all_losses = []\n",
        "\n",
        "for opt_name in opt:\n",
        "    Xtr_km, Xte_km = kmeans_features(Xtr, Xte, n_clusters=8)\n",
        "\n",
        "    Xtr_km = torch.tensor(Xtr_km, dtype=torch.float32)\n",
        "    Xte_km = torch.tensor(Xte_km, dtype=torch.float32)\n",
        "\n",
        "    losses, metrics, elapsed_time = train_and_eval(opt_name=opt_name, lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr_km, Xte=Xte_km, ytr=ytr, yte=yte, in_dim=8)\n",
        "    all_metrics.append(metrics)\n",
        "    all_losses.append(losses)\n",
        "\n",
        "    Xtr_ae, Xte_ae = autoencoder_features(Xtr, Xte, epochs=100, lr=1e-3)\n",
        "\n",
        "    losses, metrics, elapsed_time = train_and_eval(opt_name=opt_name, lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr_ae, Xte=Xte_ae, ytr=ytr, yte=yte, in_dim=8)\n",
        "    all_metrics.append(metrics)\n",
        "    all_losses.append(losses)\n",
        "\n",
        "    Xtr_pca, Xte_pca, n_components = pca_features(Xtr, Xte, var_threshold=0.95)\n",
        "\n",
        "    Xtr_pca = torch.tensor(Xtr_pca, dtype=torch.float32)\n",
        "    Xte_pca = torch.tensor(Xte_pca, dtype=torch.float32)\n",
        "\n",
        "    losses, metrics, elapsed_time = train_and_eval(opt_name=opt_name, lr=0.01, epochs=100, momentum=0.9, Xtr=Xtr_pca, Xte=Xte_pca, ytr=ytr, yte=yte, in_dim=n_components)\n",
        "    all_metrics.append(metrics)\n",
        "    all_losses.append(losses)"
      ],
      "metadata": {
        "id": "fVEI40sFJvpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = ['KMeans', 'Autoencoder', 'PCA']\n",
        "optimizers = [\"adam\", \"sgd\", \"momentum\", \"rmsprop\"]\n",
        "\n",
        "metric_names = list(all_metrics[0].keys())  # e.g., ['acc', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Convert metrics to a structured array: optimizers x features x metrics\n",
        "metrics_array = {metric: np.zeros((len(optimizers), len(feature_names))) for metric in metric_names}\n",
        "\n",
        "for i, opt_name in enumerate(optimizers):\n",
        "    for j, feat_name in enumerate(feature_names):\n",
        "        idx = i*3 + j\n",
        "        for metric in metric_names:\n",
        "            metrics_array[metric][i, j] = all_metrics[idx][metric]\n",
        "\n",
        "x = np.arange(len(optimizers))  # optimizer positions\n",
        "width = 0.25\n",
        "\n",
        "for metric in metric_names:\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for j, feat_name in enumerate(feature_names):\n",
        "        plt.bar(x + j*width, metrics_array[metric][:, j], width=width, label=feat_name)\n",
        "    plt.xticks(x + width, optimizers)\n",
        "    plt.ylabel(metric.upper())\n",
        "    plt.title(f'{metric.upper()} Comparison Across Optimizers and Feature Sets')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{metric}_comparison.png')  # save figure\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "skip_idx = 9\n",
        "plt.figure(figsize=(16,10))\n",
        "for i, opt_name in enumerate(optimizers):\n",
        "    for j, feat_name in enumerate(feature_names):\n",
        "        idx = i*3 + j\n",
        "        if idx == skip_idx:\n",
        "            continue\n",
        "        plt.plot(all_losses[idx], label=f'{opt_name} - {feat_name}')\n",
        "plt.title('Training Loss per Optimizer and Feature Set')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NSYPlaxJJyCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "ytr_np = ytr.numpy().ravel()\n",
        "\n",
        "# PCA 2D\n",
        "pca_2d = PCA(n_components=2)\n",
        "Xtr_pca_2d = pca_2d.fit_transform(Xtr_pca)  # Xtr should be NumPy\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "for label in np.unique(ytr_np):\n",
        "    plt.scatter(Xtr_pca_2d[ytr_np == label, 0], Xtr_pca_2d[ytr_np == label, 1], label=f\"Class {label}\")\n",
        "\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.title(\"2D PCA Projection\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.savefig(\"2D_PCA.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5RSbVk6PJ8GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytr_np = ytr.numpy().ravel()\n",
        "\n",
        "# PCA 2D\n",
        "pca_2d = PCA(n_components=2)\n",
        "Xtr_ae_2d = pca_2d.fit_transform(Xtr_ae)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "for label in np.unique(ytr_np):\n",
        "    plt.scatter(Xtr_ae_2d[ytr_np == label, 0], Xtr_ae_2d[ytr_np == label, 1], label=f\"Class {label}\")\n",
        "\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.title(\"2D AE Projection\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Save figure BEFORE showing it\n",
        "plt.savefig(\"2D_AE.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kxoFJGSqJ-9Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}